{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import numpy for array operations\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To check Image Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import ImageDataGenerator for image preprocessing/augmentation\n",
    "# This basically creates multiple copies of train images by jittering(adding noise). \n",
    "# This includes rotating, zooming in, flipping, shifting, etc.\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest') # 'nearest' is kind of algorithm to fill pixel values while transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "\n",
    "img = load_img('train/train/airplanes/image_0001.jpg')  # this is a PIL image\n",
    "x = img_to_array(img)  # this is a Numpy array with shape (480, 640, 3)\n",
    "x = x.reshape((1,) + x.shape)  # this is a Numpy array with shape (1, 480, 640, 3)\n",
    "\n",
    "# Create a directory named 'preview' in which we can save augmented images. \n",
    "os.system('mkdir preview')\n",
    "\n",
    "# the .flow() command below generates batches of randomly transformed images\n",
    "# and saves the results to the `preview/` directory\n",
    "i = 0\n",
    "for batch in datagen.flow(x, batch_size=1,\n",
    "                          save_to_dir='preview', save_prefix='airplanes', save_format='jpg'):\n",
    "    i += 1\n",
    "    if i > 20:\n",
    "        break  # otherwise the generator would loop indefinitely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(398, 164)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(150, 150, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 148, 148, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 72, 72, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 72, 72, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 34, 34, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 34, 34, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 17, 17, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 18496)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                1183808   \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                650       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,240,778\n",
      "Trainable params: 1,240,778\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3724 images belonging to 10 classes.\n",
      "Found 251 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "# This is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "# This is the augmentation configuration we will use for testing:\n",
    "# Only rescaling. Other transformations are not required for testing. Duh!\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# this is a generator that will read pictures found in\n",
    "# subfolers of 'data/train', and indefinitely generate\n",
    "# batches of augmented image data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'train/train',  # this is the target directory\n",
    "        target_size=(150, 150),  # all images will be resized to 150x150\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')  # since we use binary_crossentropy loss, we need binary labels\n",
    "\n",
    "# this is a similar generator, for validation data\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        'train/val',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3/3 [==============================] - 30s 10s/step - loss: 3.4128 - acc: 0.1146 - val_loss: 2.3033 - val_acc: 0.1036\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 31s 10s/step - loss: 2.2818 - acc: 0.1250 - val_loss: 2.4676 - val_acc: 0.1315\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 34s 11s/step - loss: 2.1541 - acc: 0.2500 - val_loss: 2.3567 - val_acc: 0.2191\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 36s 12s/step - loss: 2.2061 - acc: 0.2083 - val_loss: 2.4593 - val_acc: 0.0956\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 32s 11s/step - loss: 2.1970 - acc: 0.2396 - val_loss: 2.2502 - val_acc: 0.1036\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 31s 10s/step - loss: 2.0516 - acc: 0.3229 - val_loss: 2.1992 - val_acc: 0.2151\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 30s 10s/step - loss: 1.9552 - acc: 0.3646 - val_loss: 2.1456 - val_acc: 0.1833\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 32s 11s/step - loss: 2.0919 - acc: 0.3542 - val_loss: 2.0893 - val_acc: 0.2869\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 33s 11s/step - loss: 1.8388 - acc: 0.3750 - val_loss: 2.2106 - val_acc: 0.2988\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 31s 10s/step - loss: 1.5596 - acc: 0.5000 - val_loss: 2.6255 - val_acc: 0.3386\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 35s 12s/step - loss: 1.7885 - acc: 0.4375 - val_loss: 2.0769 - val_acc: 0.3147\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 32s 11s/step - loss: 1.9506 - acc: 0.4271 - val_loss: 2.2244 - val_acc: 0.2151\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 33s 11s/step - loss: 1.7352 - acc: 0.5000 - val_loss: 1.9544 - val_acc: 0.3108\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 30s 10s/step - loss: 1.6783 - acc: 0.3854 - val_loss: 2.0153 - val_acc: 0.3028\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 30s 10s/step - loss: 1.6277 - acc: 0.4583 - val_loss: 1.9489 - val_acc: 0.2789\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 31s 10s/step - loss: 1.4802 - acc: 0.5729 - val_loss: 1.8179 - val_acc: 0.3665\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 33s 11s/step - loss: 1.4444 - acc: 0.5625 - val_loss: 1.7910 - val_acc: 0.3466\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 27s 9s/step - loss: 1.4395 - acc: 0.4648 - val_loss: 1.9817 - val_acc: 0.2908\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 35s 12s/step - loss: 1.5371 - acc: 0.4896 - val_loss: 1.9697 - val_acc: 0.3267\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 31s 10s/step - loss: 1.3770 - acc: 0.5729 - val_loss: 1.6267 - val_acc: 0.3865\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 33s 11s/step - loss: 1.5035 - acc: 0.5104 - val_loss: 1.6509 - val_acc: 0.3825\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 32s 11s/step - loss: 1.2019 - acc: 0.5625 - val_loss: 2.0623 - val_acc: 0.4143\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 32s 11s/step - loss: 2.1414 - acc: 0.3646 - val_loss: 1.6397 - val_acc: 0.4422\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 32s 11s/step - loss: 1.3196 - acc: 0.6562 - val_loss: 1.6016 - val_acc: 0.4422\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 32s 11s/step - loss: 0.9302 - acc: 0.7188 - val_loss: 1.5795 - val_acc: 0.4382\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 33s 11s/step - loss: 1.2249 - acc: 0.5417 - val_loss: 1.4471 - val_acc: 0.4422\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 33s 11s/step - loss: 1.3911 - acc: 0.4688 - val_loss: 1.3712 - val_acc: 0.5418\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 32s 11s/step - loss: 1.0996 - acc: 0.6458 - val_loss: 1.5316 - val_acc: 0.4263\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 31s 10s/step - loss: 1.3901 - acc: 0.5625 - val_loss: 1.6023 - val_acc: 0.4382\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 31s 10s/step - loss: 1.0471 - acc: 0.6667 - val_loss: 1.2448 - val_acc: 0.5339\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 34s 11s/step - loss: 0.8209 - acc: 0.7500 - val_loss: 1.4527 - val_acc: 0.4582\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 31s 10s/step - loss: 0.9469 - acc: 0.6667 - val_loss: 1.4097 - val_acc: 0.5219\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 31s 10s/step - loss: 1.1734 - acc: 0.6354 - val_loss: 1.2871 - val_acc: 0.5139\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 31s 10s/step - loss: 1.0540 - acc: 0.6458 - val_loss: 1.2429 - val_acc: 0.5618\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 30s 10s/step - loss: 1.0486 - acc: 0.6667 - val_loss: 1.4578 - val_acc: 0.4940\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 30s 10s/step - loss: 1.3783 - acc: 0.5833 - val_loss: 1.3466 - val_acc: 0.5100\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 32s 11s/step - loss: 0.9600 - acc: 0.7188 - val_loss: 1.1901 - val_acc: 0.5737\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 30s 10s/step - loss: 1.2132 - acc: 0.6146 - val_loss: 1.1961 - val_acc: 0.5936\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 36s 12s/step - loss: 1.0894 - acc: 0.6771 - val_loss: 1.2531 - val_acc: 0.5896\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 30s 10s/step - loss: 1.0926 - acc: 0.6042 - val_loss: 1.3278 - val_acc: 0.4861\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 30s 10s/step - loss: 1.0222 - acc: 0.6771 - val_loss: 1.0353 - val_acc: 0.6494\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 33s 11s/step - loss: 1.2039 - acc: 0.5833 - val_loss: 1.3354 - val_acc: 0.4542\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 34s 11s/step - loss: 1.1910 - acc: 0.6146 - val_loss: 1.0601 - val_acc: 0.6335\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 34s 11s/step - loss: 1.0631 - acc: 0.6354 - val_loss: 1.0364 - val_acc: 0.6534\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 35s 12s/step - loss: 0.7171 - acc: 0.7396 - val_loss: 0.9777 - val_acc: 0.6534\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 35s 12s/step - loss: 0.9905 - acc: 0.6354 - val_loss: 2.0057 - val_acc: 0.3227\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 36s 12s/step - loss: 1.2299 - acc: 0.6146 - val_loss: 1.2368 - val_acc: 0.5299\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 35s 12s/step - loss: 1.0117 - acc: 0.6562 - val_loss: 1.1420 - val_acc: 0.6215\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 30s 10s/step - loss: 0.9646 - acc: 0.6458 - val_loss: 1.1229 - val_acc: 0.5737\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 32s 11s/step - loss: 0.6961 - acc: 0.7396 - val_loss: 1.1255 - val_acc: 0.5857\n"
     ]
    }
   ],
   "source": [
    "# fit_generator is similar to 'fit'. But instead of x_train and y_train, we pass 'train_generator' \n",
    "# which already has the samples and their corresponding target information.\n",
    "\n",
    "# 'step' here is one mini-batch\n",
    "# 'steps_per_epoch' is number of batches per epoch.\n",
    "# Typically 'steps_per_epoch' should be total_samples divided by batch_size\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=120//batch_size, # '//' in python returns only the quotient\n",
    "        epochs=50,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=80//batch_size)\n",
    "model.save_weights('model_img.h5')  # always save your weights after training or during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'BACKGROUND_Google': 0, 'Faces': 1, 'Faces_easy': 2, 'Leopards': 3, 'Motorbikes': 4, 'airplanes': 5, 'bonsai': 6, 'car_side': 7, 'grand_piano': 8, 'watch': 9}\n"
     ]
    }
   ],
   "source": [
    "# print(train_generator.filenames)\n",
    "print(train_generator.class_indices) # This returns class labels of directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = test_datagen.flow_from_directory(\n",
    "        'test/',  # this is the target directory\n",
    "        target_size=(150, 150),  # all images will be resized to 150x150\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical', shuffle = False)  # since we use crossentropy loss, we need binary labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 7 4 4 4 4 4 4 4 4 2 4 4 4 4 0 8 4 4 5 4 4 4 4 4 4 4 4 4 4]\n"
     ]
    }
   ],
   "source": [
    "test_prob = model.predict_generator(test_generator, steps=1) # this returns the probabilities\n",
    "test_pred_classes = np.argmax(test_prob, axis=1) # convert probabilities to classes\n",
    "print(test_pred_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\\image_0002.jpg\n"
     ]
    }
   ],
   "source": [
    "# Check the corresponding filenames of the predictions\n",
    "print(test_generator.filenames[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "test_predictions = pd.DataFrame(data=np.vstack((test_generator.filenames, test_pred_classes)).T, \n",
    "                                columns=['file', 'label'])\n",
    "\n",
    "test_predictions.to_csv('test_submission.csv', header=True, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
